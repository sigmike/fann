<!-- $Id: fann.xml,v 1.3 2004/02/16 09:50:45 tadpole9 Exp $ -->
<?xml version='1.0' encoding='ISO-8859-1' ?>
<!DOCTYPE book PUBLIC "-//OASIS//DTD DocBook XML V4.1.2//EN" "docbook/xml-dtd-4.1.2/docbookx.dtd">
<book>
 <bookinfo id="bookinfo">
  <title>Fast Artificial Neural Network Library</title>
  <authorgroup id="authors">
   <author>
    <firstname>Steffen</firstname>
    <surname>Nissen</surname>
   </author>
   <author>
    <firstname>Evan</firstname>
    <surname>Nemerson</surname>
   </author>
  </authorgroup>
  <copyright>
   <year>2004</year>
  </copyright>
 </bookinfo>

 <chapter id="intro">
  <title>Introduction</title>
  <para>
   fann - Fast Artificial Neural Network Library is written in ANSI C. The
   library implements multilayer feedforward ANNs, up to 150 times faster
   than other libraries. FANN supports execution in fixed point, for fast
   execution on systems like the iPAQ.
  </para>

  <section id="intro.install">
   <title>Installation</title>

   <section id="intro.install.rpm">
    <title>RPMs</title>
    <para>
     RPMs are a simple way to manage packages, and is used on many common
     Linux distributions such as <ulink url="http://www.redhat.com">Red Hat</ulink>
     and <ulink url="http://www.mandrake.com/">Mandrake</ulink>.
    </para>
    <para>
     After downloading FANN, simply run (as root) the following command:
     <command>rpm -ivh $PATH_TO_RPM</command>
    </para>
   </section>

   <section id="intro.install.deb">
    <title>DEBs</title>
    <para>
     Dunno- never used dpkg. Steffen?
    </para>
   </section>

   <section id="intro.install.win32">
    <title>Windows</title>
    <para>
     Instructions for Borland & VC++
    </para>
   </section>

   <section id="intro.install.src">
    <title>Compiling from source</title>
    <para>
     Compiling FANN from source code entails the standard GNU autotools technique. First,
     configure the package as you want it by typing (in the FANN directory), <command>
     ./configure</command> If you need help choosing the options you would like to use,
     try <command>./configure --help</command>
    </para>
    <para>
     Next, you have to actually compile the library. To do this, simply type <command>make
     </command>
    </para>
    <para>
     Finally, to install the library, type <command>make install</command> Odds are you will
     have to be root to install, so you may need to <command>su</command> to root before installing.
     Please remember to log out of the root account immediately after <command>make install
     </command> finishes.
    </para>
   </section>
  </section>

  <section id="intro.start">
   <title>Getting Started</title>
   <para>
    An ANN is normally run in two different modes, a training mode and an execution mode.
    Although it is possible to do this in the same program, I will recommend doing it in two
    different programs.
   </para>
   <para>
    There are several reasons to why it is usually a good idea to write the training and
    execution in two different programs, but the most obvious is the fact that a typical ANN
    system is only trained once, while it is executed many times.
   </para>
   <section id="intro.start.train">
    <title>Training</title>
    <para>
     The following is a simple program which trains an ANN with a data set and then saves the
     ANN to a file.
     <example>
      <title>Simple training example</title>
      <programlisting>
<![CDATA[
#include "fann.h"

int main()
{
	const float connection_rate = 1;
	const float learning_rate = 0.7;
	const unsigned int num_input = 2;
	const unsigned int num_output = 1;
	const unsigned int num_layers = 3;
	const unsigned int num_neurons_hidden = 4;
	const float desired_error = 0.0001;
	const unsigned int max_iterations = 500000;
	const unsigned int iterations_between_reports = 1000;

	struct fann *ann = fann_create(connection_rate, learning_rate, num_layers,
		num_input, num_neurons_hidden, num_output);
	
	fann_train_on_file(ann, "xor.data", max_iterations,
		iterations_between_reports, desired_error);
	
	fann_save(ann, "xor_float.net");
	
	fann_destroy(ann);

	return 0;
}
]]>
      </programlisting>
     </example>
    </para>
    <para>
     The file xor.data, used to train the xor function:
     <literallayout>
4 2 1
0 0
0
0 1
1
1 0
1
1 1
0
     </literallayout>The first line consists of three numbers:
     The first is the number of training pairs in the file, the
     second is the number of inputs and the third is the number
     of outputs. The rest of the file is the actual training data,
     consisting of one line with inputs, one with outputs etc.
    </para>
    <para>
     TODO: Link up functions to API reference.
    </para>
   </section>

   <section id="intro.start.execution">
    <title>Execution</title>
    <para>
     The following example shows a simple program which executes a single
     input on the ANN. The program introduces two new functions which were
     not used in the traiining procedure, as well as the fann_type type.
     <example>
      <title>Simple training example</title>
      <programlisting>
<![CDATA[
#include <stdio.h>
#include "floatfann.h"

int main()
{
	fann_type *calc_out;
	fann_type input[2];

	struct fann *ann = fann_create_from_file("xor_float.net");
	
	input[0] = 0;
	input[1] = 1;
	calc_out = fann_run(ann, input);

	printf("xor test (%f,%f) -> %f\n",
		input[0], input[1], *calc_out);
	
	fann_destroy(ann);
	return 0;
}
]]>
      </programlisting>
     </example>
    </para>
   </section>
  </section>
 </chapter>

 <chapter id="theory">
  <title>Neural Network Theory</title>
  <para>
   This section will briefly explain the theory of neural networks (hereafter known
   as NN) and artificial neural networks (hereafter known as ANN). For a more in depth
   explanation of these concepts please consult the literature;
   <xref linkend="bib.hassoun_1995" endterm="bib.hassoun_1995.abbrev"/> has good coverage
   of most concepts of ANN and <xref linkend="bib.hertz_1991" endterm="bib.hertz_1991.abbrev"/>
   describes the mathematics of ANN very thoroughly, while
   <xref linkend="bib.anderson_1995" endterm="bib.anderson_1995.abbrev"/> has a more
   psychological and physiological approach to NN and ANN. For the pragmatic I could recommend
   <xref linkend="bib.tettamanzi_2001" endterm="bib.tettamanzi_2001.abbrev"/>, which has a short
   and easily understandable introduction to NN and ANN.
  </para>

  <section id="theory.neural_networks">
   <title>Neural Networks</title>

   <para>
    The human brain is a highly complicated machine capable of solving very complex problems.
    Although we have a good understanding of some of the basic operations that drive the brain,
    we are still far from understanding everything there is to know about the brain. 
   </para>
   <para>
    In order to understand ANN, you will need to have a basic knowledge of how the internals of
    the brain work. The brain is part of the central nervous system and consists of a very large
    NN. The NN is actually quite complicated, but I will only include the details needed to
    understand ANN, in order to simplify the explanation. 
   </para>
   <para>
    The NN is a network consisting of connected neurons. The center of the neuron is called the
    nucleus. The nucleus is connected to other nucleuses by means of the dendrites and the axon.
    This connection is called a synaptic connection.
   </para>
   <para>
    The neuron can fire electric pulses through its synaptic connections, which is received at
    the dendrites of other neurons.
   </para>
   <para>
    When a neuron receives enough electric pulses through its dendrites, it activates and fires a
    pulse through its axon, which is then received by other neurons. In this way information can
    propagate through the NN. The synaptic connections change throughout the lifetime of a neuron
    and the amount of incoming pulses needed to activate a neuron (the threshold) also change. This
    behavior allows the NN to learn.
   </para>
   <para>
    The human brain consists of around 10^11 neurons which are highly interconnected with around
    10^15 connections <xref linkend="bib.tettamanzi_2001" endterm="bib.tettamanzi_2001.abbrev"/>.
    These neurons activates in parallel as an effect to internal and external sources. The brain is
    connected to the rest of the nervous system, which allows it to receive information by means of
    the five senses and also allows it to control the muscles.
   </para>
  </section>

  <section id="theory.artificial_neural_networks">
   <title>Artificial Neural Networks</title>
    <para>
     It is not possible (at the moment) to make an artificial brain, but it is possible to make
     simplified artificial neurons and artificial neural networks. These ANNs can be made in many
     different ways and can try to mimic the brain in many different ways.
   </para>
   <para>
    ANNs are not intelligent, but they are good for recognizing patterns and making simple rules for
    complex problems. They also have excellent training capabilities which is why they are often used
    in artificial intelligence research.
   </para>
   <para>
    ANNs are good at generalizing from a set of training data. E.g. this means an ANN given data about
    a set of animals connected to a fact telling if they are mammals or not, is able to predict whether
    an animal outside the original set is a mammal from its data. This is a very desirable feature of
    ANNs, because you do not need to know the characteristics defining a mammal, the ANN will find out
    by itself.
   </para>
  </section>

  <section id="theory.training">
   <title>Training an ANN</title>

   <para>
    When training an ANN with a set of input and output data, we wish to adjust the weights in the ANN,
    to make the ANN give the same outputs as seen in the training data. On the other hand, we do not
    want to make the ANN too specific, making it give precise results for the training data, but incorrect
    results for all other data. When this happens, we say that the ANN has been over-fitted.
   </para>
   <para>
    The training process can be seen as an optimization problem, where we wish to minimize the mean square
    error of the entire set of training data. This problem can be solved in many different ways, ranging
    from standard optimization heuristics like simulated annealing, through more special optimization
    techniques like genetic algorithms to specialized gradient descent algorithms like backpropagation. 
   </para>
   <para>
    The most used algorithm is the backpropagation algorithm, but this algorithm has some limitations
    concerning, the extent of adjustment to the weights in each iteration. This problem has been solved in
    more advanced algorithms like RPROP
    <xref linkend="bib.riedmiller_1993" endterm="bib.riedmiller_1993.abbrev"/> and quickprop
    <xref linkend="bib.fahlman_1988" endterm="bib.fahlman_1988.abbrev"/>, but I will not elaborate further
    on these algorithms.
   </para>
  </section>
 </chapter>

 <chapter id="api">
  <title>API Reference</title>
  <para>
   This is a list of all functions in FANN.
  </para>

  <section id="api.sec.create_destroy">
   <title>Creation and Destruction</title>

   <refentry id="api.fann_create">
    <refnamediv>
     <refname>fann_create</refname>
     <refpurpose>Save an artificial neural network to a file.</refpurpose>
    </refnamediv>
    <refsect1>
     <title>Description</title>
      <methodsynopsis>
       <type>struct fann *</type><methodname>fann_create</methodname>
       <methodparam><type>float</type><parameter>connection_rate</parameter></methodparam>
       <methodparam><type>float</type><parameter>learning_rate</parameter></methodparam>
       <methodparam><type>unsigned int</type><parameter>num_layers</parameter></methodparam>
       <methodparam><type>unsigned int</type><parameter>...</parameter></methodparam>
      </methodsynopsis>
     <para>
      <function>fann_create</function> will create a new artificial neural network, and return
      a pointer to it.
     </para>
    </refsect1>
   </refentry>

   <refentry id="api.fann_create_array">
    <refnamediv>
     <refname>fann_create_array</refname>
     <refpurpose>Save an artificial neural network to a file.</refpurpose>
    </refnamediv>
    <refsect1>
     <title>Description</title>
      <methodsynopsis>
       <type>struct fann *</type><methodname>fann_create_array</methodname>
       <methodparam><type>float</type><parameter>connection_rate</parameter></methodparam>
       <methodparam><type>float</type><parameter>learning_rate</parameter></methodparam>
       <methodparam><type>unsigned int</type><parameter>num_layers</parameter></methodparam>
       <methodparam><type>unsigned int *</type><parameter>neurons_per_layer</parameter></methodparam>
      </methodsynopsis>
     <para>
      <function>fann_create_array</function> will create a new artificial neural network, and return
      a pointer to it. It is the same as <function>fann_create</function>, only it accepts an array
      as its final parameter instead of variable arguments.
     </para>
    </refsect1>
   </refentry>

   <refentry id="api.fann_destroy">
    <refnamediv>
     <refname>fann_destroy</refname>
     <refpurpose>Destroy an ANN.</refpurpose>
    </refnamediv>
    <refsect1>
     <title>Description</title>
      <methodsynopsis>
       <type>void</type><methodname>fann_destroy</methodname>
       <methodparam><type>struct fann *</type><parameter>ann</parameter></methodparam>
      </methodsynopsis>
     <para>
      <function>fann_destroy</function> will destroy an artificial neural network, properly
      freeing all associated memory.
     </para>
    </refsect1>
   </refentry>

   <refentry id="api.fann_run">
    <refnamediv>
     <refname>fann_run</refname>
     <refpurpose>Run an ANN.</refpurpose>
    </refnamediv>
    <refsect1>
     <title>Description</title>
      <methodsynopsis>
       <type>fann_type *</type><methodname>fann_run</methodname>
       <methodparam><type>struct fann *</type><parameter>ann</parameter></methodparam>
       <methodparam><type>fann_type *</type><parameter>input</parameter></methodparam>
      </methodsynopsis>
     <para>
      <function>fann_run</function> will run <parameter>input</parameter> through
      <parameter>ann</parameter>, returning an array of outputs, the number of which
      being equal to the number of neurons in the output layer.
     </para>
    </refsect1>
   </refentry>
  </section>

  <section id="api.sec.io">
   <title>Input/Output</title>

   <refentry id="api.fann_save">
    <refnamediv>
     <refname>fann_save</refname>
     <refpurpose>Save an ANN to a file.</refpurpose>
    </refnamediv>
    <refsect1>
     <title>Description</title>
      <methodsynopsis>
       <type>void</type><methodname>fann_save</methodname>
       <methodparam><type>struct fann *</type><parameter>ann</parameter></methodparam>
       <methodparam><type>const char *</type><parameter>configuration_file</parameter></methodparam>
      </methodsynopsis>
     <para>
      <function>fann_save</function> will attempt to save <parameter>ann</parameter>
      to the file located at <parameter>configuration_file</parameter>
     </para>
    </refsect1>
   </refentry>

   <refentry id="api.fann_save_to_fixed">
    <refnamediv>
     <refname>fann_save_to_fixed</refname>
     <refpurpose>Save an ANN to a fixed-point file.</refpurpose>
    </refnamediv>
    <refsect1>
     <title>Description</title>
      <methodsynopsis>
       <type>void</type><methodname>fann_save_to_fixed</methodname>
       <methodparam><type>struct fann *</type><parameter>ann</parameter></methodparam>
       <methodparam><type>const char *</type><parameter>configuration_file</parameter></methodparam>
      </methodsynopsis>
     <para>
      <function>fann_save_fixed</function> will attempt to save <parameter>ann</parameter>
      to the file located at <parameter>configuration_file</parameter> as a fixed-point netowrk.
     </para>
    </refsect1>
   </refentry>

   <refentry id="api.fann_create_from_file">
    <refnamediv>
     <refname>fann_create_from_file</refname>
     <refpurpose>Load an ANN from a file..</refpurpose>
    </refnamediv>
    <refsect1>
     <title>Description</title>
      <methodsynopsis>
       <type>struct fann *</type><methodname>fann_create_from_file</methodname>
       <methodparam><type>const char *</type><parameter>configuration_file</parameter></methodparam>
      </methodsynopsis>
     <para>
      <function>fann_create_from_file</function> will attempt to load an artificial neural netowrk
      from a file.
     </para>
    </refsect1>
   </refentry>
  </section>

  <section id="api.sec.train_algo">
   <title>Training</title>

   <refentry id="api.fann_train">
    <refnamediv>
     <refname>fann_train</refname>
     <refpurpose>Train an ANN.</refpurpose>
    </refnamediv>
    <refsect1>
     <title>Description</title>
      <methodsynopsis>
       <type>void</type><methodname>fann_train</methodname>
       <methodparam><type>struct fann *</type><parameter>ann</parameter></methodparam>
       <methodparam><type>fann_type *</type><parameter>input</parameter></methodparam>
       <methodparam><type>fann_type *</type><parameter>output</parameter></methodparam>
      </methodsynopsis>
     <para>
      <function>fann_train</function> will train one iteration with a set of inputs, and
      a set of desired outputs.
     </para>
    </refsect1>
   </refentry>

   <refentry id="api.fann_test">
    <refnamediv>
     <refname>fann_test</refname>
     <refpurpose>Tests an ANN.</refpurpose>
    </refnamediv>
    <refsect1>
     <title>Description</title>
      <methodsynopsis>
       <type>fann_type *</type><methodname>fann_test</methodname>
       <methodparam><type>struct fann *</type><parameter>ann</parameter></methodparam>
       <methodparam><type>fann_type *</type><parameter>input</parameter></methodparam>
       <methodparam><type>fann_type *</type><parameter>desired_error</parameter></methodparam>
      </methodsynopsis>
     <para>
      Test with a set of inputs, and a set of desired outputs.
      This operation updates the mean square error, but does not
      change the network in any way.
     </para>
    </refsect1>
   </refentry>

   <refentry id="api.fann_get_MSE">
    <refnamediv>
     <refname>fann_get_MSE</refname>
     <refpurpose>Return the mean square error of an ANN.</refpurpose>
    </refnamediv>
    <refsect1>
     <title>Description</title>
      <methodsynopsis>
       <type>float</type><methodname>fann_get_MSE</methodname>
       <methodparam><type>struct fann *</type><parameter>ann</parameter></methodparam>
      </methodsynopsis>
     <para>
      Reads the mean square error from the network.
     </para>
    </refsect1>
   </refentry>

   <refentry id="api.fann_reset_MSE">
    <refnamediv>
     <refname>fann_reset_MSE</refname>
     <refpurpose>Reset the mean square error of an ANN.</refpurpose>
    </refnamediv>
    <refsect1>
     <title>Description</title>
      <methodsynopsis>
       <type>void</type><methodname>fann_reset_MSE</methodname>
       <methodparam><type>struct fann *</type><parameter>ann</parameter></methodparam>
      </methodsynopsis>
     <para>
      Resets the mean square error from the network.
     </para>
    </refsect1>
   </refentry>
  </section>

  <section id="api.sec.train_data">
   <title>Training Data</title>

   <refentry id="api.fann_read_train_from_file">
    <refnamediv>
     <refname>fann_read_train_from_file</refname>
     <refpurpose>Read training data from a file.</refpurpose>
    </refnamediv>
    <refsect1>
    <title>Description</title>
     <methodsynopsis>
      <type>struct fann_train_data *</type><methodname>fann_read_train_from_file</methodname>
      <methodparam><type>char *</type><parameter>filename</parameter></methodparam>
     </methodsynopsis>
     <para>
      <function>fann_read_train_from_file</function> will load training data from a file.
    </para>
    </refsect1>
   </refentry>

   <refentry id="api.fann_destroy_train">
    <refnamediv>
     <refname>fann_destroy_train</refname>
    <refpurpose>Destroy training data.</refpurpose>
    </refnamediv>
    <refsect1>
     <title>Description</title>
     <methodsynopsis>
     <type>void</type><methodname>fann_destroy_train_data</methodname>
      <methodparam><type>struct fann_train_data *</type><parameter>train_data</parameter></methodparam>
     </methodsynopsis>
     <para>
      Destroy the training data stored in <parameter>train_data</parameter>, freeing the associated memory.
    </para>
    </refsect1>
   </refentry>

   <refentry id="api.fann_train_on_data">
    <refnamediv>
     <refname>fann_train_on_data</refname>
    <refpurpose>Train an ANN.</refpurpose>
    </refnamediv>
    <refsect1>
     <title>Description</title>
     <methodsynopsis>
      <type>void</type><methodname>fann_train_on_data</methodname>
      <methodparam><type>struct fann *</type><parameter>ann</parameter></methodparam>
      <methodparam><type>struct fann_train_data *</type><parameter>data</parameter></methodparam>
      <methodparam><type>unsigned int</type><parameter>max_epochs</parameter></methodparam>
      <methodparam><type>unsigned int</type><parameter>epochs_between_reports</parameter></methodparam>
      <methodparam><type>float</type><parameter>desired_error</parameter></methodparam>
     </methodsynopsis>
     <para>
      Trains <parameter>ann</parameter> using <parameter>data</parameter> until <parameter>desired_error</parameter>
      is reached, or until <parameter>max_epochs</parameter> is surpassed.
     </para>
    </refsect1>
   </refentry>

   <refentry id="api.fann_train_on_data_callback">
    <refnamediv>
     <refname>fann_train_on_data_callback</refname>
     <refpurpose>Train an ANN.</refpurpose>
    </refnamediv>
    <refsect1>
     <title>Description</title>
     <methodsynopsis>
      <type>void</type><methodname>fann_train_on_data_callback</methodname>
      <methodparam><type>struct fann *</type><parameter>ann</parameter></methodparam>
      <methodparam><type>struct fann_train_data *</type><parameter>data</parameter></methodparam>
      <methodparam><type>unsigned int</type><parameter>max_epochs</parameter></methodparam>
      <methodparam><type>unsigned int</type><parameter>epochs_between_reports</parameter></methodparam>
      <methodparam><type>float</type><parameter>desired_error</parameter></methodparam>
      <methodparam><type>int</type><parameter>(*callback)(unsigned int epochs, float error)</parameter></methodparam>
     </methodsynopsis>
     <para>
      Trains <parameter>ann</parameter> using <parameter>data</parameter> until <parameter>desired_error</parameter>
      is reached, or until <parameter>max_epochs</parameter> is surpassed.
     </para>
     <para>
      This function behaves identically to <link linkend="api.fann_train_on_data"><function>fann_train_on_data</function></link>,
      except that <function>fann_train_on_data_callback</function> allows you to specify a function to be called every
      <parameter>epochs_between_reports</parameter> instead of using the default reporting mechanism.
     </para>
    </refsect1>
   </refentry>

   <refentry id="api.fann_train_on_file">
    <refnamediv>
     <refname>fann_train_on_file</refname>
     <refpurpose>Train an ANN.</refpurpose>
    </refnamediv>
    <refsect1>
     <title>Description</title>
     <methodsynopsis>
      <type>void</type><methodname>fann_train_on_file</methodname>
      <methodparam><type>struct fann *</type><parameter>ann</parameter></methodparam>
      <methodparam><type>char *</type><parameter>filename</parameter></methodparam>
      <methodparam><type>unsigned int</type><parameter>max_epochs</parameter></methodparam>
      <methodparam><type>unsigned int</type><parameter>epochs_between_reports</parameter></methodparam>
      <methodparam><type>float</type><parameter>desired_error</parameter></methodparam>
     </methodsynopsis>
     <para>
      Trains <parameter>ann</parameter> using the data in <parameter>filename</parameter> until
      <parameter>desired_error</parameter> is reached, or until <parameter>max_epochs</parameter>
      is surpassed.
     </para>
    </refsect1>
   </refentry>

   <refentry id="api.fann_train_on_file_callback">
    <refnamediv>
     <refname>fann_train_on_file_callback</refname>
     <refpurpose>Train an ANN.</refpurpose>
    </refnamediv>
    <refsect1>
     <title>Description</title>
     <methodsynopsis>
      <type>void</type><methodname>fann_train_on_file_callback</methodname>
      <methodparam><type>struct fann *</type><parameter>ann</parameter></methodparam>
      <methodparam><type>char *</type><parameter>filename</parameter></methodparam>
      <methodparam><type>unsigned int</type><parameter>max_epochs</parameter></methodparam>
      <methodparam><type>unsigned int</type><parameter>epochs_between_reports</parameter></methodparam>
      <methodparam><type>float</type><parameter>desired_error</parameter></methodparam>
      <methodparam><type>int</type><parameter>(*callback)(unsigned int epochs, float error)</parameter></methodparam>
     </methodsynopsis>
     <para>
      Trains <parameter>ann</parameter> using the data in <parameter>filename</parameter> until
      <parameter>desired_error</parameter> is reached, or until <parameter>max_epochs</parameter>
      is surpassed.
     </para>
     <para>
      This function behaves identically to <link linkend="api.fann_train_on_file"><function>fann_train_on_file</function></link>,
      except that <function>fann_train_on_file_callback</function> allows you to specify a function to be called every
      <parameter>epochs_between_reports</parameter> instead of using the default reporting mechanism.
     </para>
    </refsect1>
   </refentry>

   <refentry id="api.fann_shuffle_train_data">
    <refnamediv>
     <refname>fann_shuffle_train_data</refname>
     <refpurpose>Shuffle the training data.</refpurpose>
    </refnamediv>
    <refsect1>
     <title>Description</title>
     <methodsynopsis>
      <type>void</type><methodname>fann_shuffle_train_data</methodname>
      <methodparam><type>struct fann_train_data *</type><parameter>data</parameter></methodparam>
     </methodsynopsis>
     <para>
      <function>fann_shuffle_train_data</function> will randomize the order of the training data
      contained in <parameter>data</parameter>.
     </para>
    </refsect1>
   </refentry>

   <refentry id="api.fann_merge_train_data">
    <refnamediv>
     <refname>fann_merge_train_data</refname>
     <refpurpose>Merge two sets of training data.</refpurpose>
    </refnamediv>
    <refsect1>
     <title>Description</title>
     <methodsynopsis>
      <type>struct fann_train_data *</type><methodname>fann_merge_train_data</methodname>
      <methodparam><type>struct fann_train_data *</type><parameter>data1</parameter></methodparam>
      <methodparam><type>struct fann_train_data *</type><parameter>data2</parameter></methodparam>
     </methodsynopsis>
     <para>
      <function>fann_merge_train_data</function> will return a single set of training data which
      contains all data from <parameter>data1</parameter> and <parameter>data2</parameter>.
     </para>
    </refsect1>
   </refentry>

   <refentry id="api.fann_duplicate_train_data">
    <refnamediv>
     <refname>fann_duplicate_train_data</refname>
     <refpurpose>Copies a set of training data.</refpurpose>
    </refnamediv>
    <refsect1>
     <title>Description</title>
     <methodsynopsis>
      <type>struct fann_train_data *</type><methodname>fann_duplicate_train_data</methodname>
      <methodparam><type>struct fann_train_data *</type><parameter>data</parameter></methodparam>
     </methodsynopsis>
     <para>
      <function>fann_duplicate_train_data</function> will return a copy of <parameter>data</parameter>.
     </para>
    </refsect1>
   </refentry>
  </section>

  <section id="api.sec.options">
   <title>Options</title>

   <refentry id="api.fann_get_learning_rate">
    <refnamediv>
     <refname>fann_get_learning_rate</refname>
     <refpurpose>Retrieve learning rate from a network.</refpurpose>
    </refnamediv>
    <refsect1>
     <title>Description</title>
     <methodsynopsis>
      <type>float</type><methodname>fann_get_learning_rate</methodname>
      <methodparam><type>struct fann *</type><parameter>ann</parameter></methodparam>
     </methodsynopsis>
     <para>
      Return the learning rate for a given network.
     </para>
    </refsect1>
   </refentry>

   <refentry id="api.fann_set_learning_rate">
    <refnamediv>
     <refname>fann_set_learning_rate</refname>
     <refpurpose>Set a network's learning rate.</refpurpose>
    </refnamediv>
    <refsect1>
     <title>Description</title>
     <methodsynopsis>
      <type></type><methodname>fann_set_learning_rate</methodname>
      <methodparam><type>struct fann *</type><parameter>ann</parameter></methodparam>
      <methodparam><type>float</type><parameter>learning_rate</parameter></methodparam>
     </methodsynopsis>
     <para>
      Set the learning rate of a network.
     </para>
    </refsect1>
   </refentry>

   <refentry id="api.fann_get_activation_function_hidden">
    <refnamediv>
     <refname>fann_get_activation_function_hidden</refname>
     <refpurpose>Get the activation function of the hidden layer.</refpurpose>
    </refnamediv>
    <refsect1>
     <title>Description</title>
     <methodsynopsis>
      <type>unsigned int</type><methodname>fann_get_activation_function_hidden</methodname>
      <methodparam><type>struct fann *</type><parameter>ann</parameter></methodparam>
     </methodsynopsis>
     <para>
      Return the activation function of the hidden layer.
     </para>
    </refsect1>
   </refentry>

   <refentry id="api.fann_set_activation_function_hidden">
    <refnamediv>
     <refname>fann_set_activation_function_hidden</refname>
     <refpurpose>Set the activation function for the hidden layer.</refpurpose>
    </refnamediv>
    <refsect1>
     <title>Description</title>
     <methodsynopsis>
      <type></type><methodname>fann_set_activation_function_hidden</methodname>
      <methodparam><type>struct fann *</type><parameter>ann</parameter></methodparam>
      <methodparam><type>unsigned int</type><parameter>activation_function</parameter></methodparam>
     </methodsynopsis>
     <para>
      Set the activation function of the hidden layer to <parameter>activation_function></parameter>.
     </para>
    </refsect1>
   </refentry>

   <refentry id="api.fann_get_activation_function_output">
    <refnamediv>
     <refname>fann_get_activation_function_output</refname>
     <refpurpose>Get the activation function of the output layer.</refpurpose>
    </refnamediv>
    <refsect1>
     <title>Description</title>
     <methodsynopsis>
      <type>unsigned int</type><methodname>fann_get_activation_function_output</methodname>
      <methodparam><type>struct fann *</type><parameter>ann</parameter></methodparam>
     </methodsynopsis>
     <para>
      Return the activation function of the output layer.
     </para>
    </refsect1>
   </refentry>

   <refentry id="api.fann_set_activation_function_output">
    <refnamediv>
     <refname>fann_set_activation_function_output</refname>
     <refpurpose>Set the activation function for the output layer.</refpurpose>
    </refnamediv>
    <refsect1>
     <title>Description</title>
     <methodsynopsis>
      <type>void</type><methodname>fann_set_activation_function_output</methodname>
      <methodparam><type>struct fann *</type><parameter>ann</parameter></methodparam>
      <methodparam><type>unsigned int</type><parameter>activation_function</parameter></methodparam>
     </methodsynopsis>
     <para>
      Set the activation function of the output layer to <parameter>activation_function></parameter>.
     </para>
    </refsect1>
   </refentry>

   <refentry id="api.fann_get_activation_hidden_steepness">
    <refnamediv>
     <refname>fann_get_activation_hidden_steepness</refname>
     <refpurpose>Retrieve the steepness of the activation function of the hidden layers.</refpurpose>
    </refnamediv>
    <refsect1>
     <title>Description</title>
     <methodsynopsis>
      <type>fann_type</type><methodname>fann_get_activation_hidden_steepness</methodname>
      <methodparam><type>struct fann *</type><parameter>ann</parameter></methodparam>
     </methodsynopsis>
     <para>
      Return the steepness of the activation function of the hidden layers.
     </para>
    </refsect1>
   </refentry>

   <refentry id="api.fann_set_activation_hidden_steepness">
    <refnamediv>
     <refname>fann_set_activation_hidden_steepness</refname>
     <refpurpose>Set the steepness of the activation function of the hidden layers.</refpurpose>
    </refnamediv>
    <refsect1>
     <title>Description</title>
     <methodsynopsis>
      <type>void</type><methodname>fann_set_activation_hidden_steepness</methodname>
      <methodparam><type>struct fann *</type><parameter>ann</parameter></methodparam>
      <methodparam><type>fann_type</type><parameter>steepness</parameter></methodparam>
     </methodsynopsis>
     <para>
      Set the steepness of the activation function of thie hidden layers of
      <parameter>ann</parameter> to <parameter>steepness</parameter>.
     </para>
    </refsect1>
   </refentry>

   <refentry id="api.fann_get_activation_output_steepness">
    <refnamediv>
     <refname>fann_get_activation_output_steepness</refname>
     <refpurpose>Retrieve the steepness of the activation function of the hidden layers.</refpurpose>
    </refnamediv>
    <refsect1>
     <title>Description</title>
     <methodsynopsis>
      <type>fann_type</type><methodname>fann_get_activation_output_steepness</methodname>
      <methodparam><type>struct fann *</type><parameter>ann</parameter></methodparam>
     </methodsynopsis>
     <para>
      Return the steepness of the activation function of the hidden layers.
     </para>
    </refsect1>
   </refentry>

   <refentry id="api.fann_set_activation_output_steepness">
    <refnamediv>
     <refname>fann_set_activation_output_steepness</refname>
     <refpurpose>Set the steepness of the activation function of the hidden layers.</refpurpose>
    </refnamediv>
    <refsect1>
     <title>Description</title>
     <methodsynopsis>
      <type>void</type><methodname>fann_set_activation_output_steepness</methodname>
      <methodparam><type>struct fann *</type><parameter>ann</parameter></methodparam>
      <methodparam><type>fann_type</type><parameter>steepness</parameter></methodparam>
     </methodsynopsis>
     <para>
      Set the steepness of the activation function of thie hidden layers of
      <parameter>ann</parameter> to <parameter>steepness</parameter>.
     </para>
    </refsect1>
   </refentry>

   <refentry id="api.fann_get_num_input">
    <refnamediv>
     <refname>fann_get_num_input</refname>
     <refpurpose>Get the number of neurons in the input layer.</refpurpose>
    </refnamediv>
    <refsect1>
     <title>Description</title>
     <methodsynopsis>
      <type>unsigned int</type><methodname>fann_get_num_input</methodname>
      <methodparam><type>struct fann *</type><parameter>ann</parameter></methodparam>
     </methodsynopsis>
     <para>
      Return the number of neurons in the input layer of <parameter>ann</parameter>.
     </para>
    </refsect1>
   </refentry>

   <refentry id="api.fann_get_num_output">
    <refnamediv>
     <refname>fann_get_num_output</refname>
     <refpurpose>Get number of neurons in the output layer.</refpurpose>
    </refnamediv>
    <refsect1>
     <title>Description</title>
     <methodsynopsis>
      <type>unsigned int</type><methodname>fann_get_num_output</methodname>
      <methodparam><type>struct fann *</type><parameter>ann</parameter></methodparam>
     </methodsynopsis>
     <para>
      Return the number of neurons in the output layer of <parameter>ann</parameter>.
     </para>
    </refsect1>
   </refentry>

   <refentry id="api.fann_get_total_neurons">
    <refnamediv>
     <refname>fann_get_total_neurons</refname>
     <refpurpose>Get the total number of neurons in a network.</refpurpose>
    </refnamediv>
    <refsect1>
     <title>Description</title>
     <methodsynopsis>
      <type>unsigned int</type><methodname>fann_get_total_neurons</methodname>
      <methodparam><type>struct fann *</type><parameter>ann</parameter></methodparam>
     </methodsynopsis>
     <para>
      Return the total number of neurons in <parameter>ann</parameter>.
     </para>
    </refsect1>
   </refentry>

   <refentry id="api.fann_get_total_connections">
    <refnamediv>
     <refname>fann_get_total_connections</refname>
     <refpurpose>Get the total number of connections in a network.</refpurpose>
    </refnamediv>
    <refsect1>
     <title>Description</title>
     <methodsynopsis>
      <type>unsigned int</type><methodname>fann_get_total_connections</methodname>
      <methodparam><type>struct fann *</type><parameter>ann</parameter></methodparam>
     </methodsynopsis>
     <para>
      Return the total number of connections in <parameter>ann</parameter>.
     </para>
    </refsect1>
   </refentry>

   <refentry id="api.fann_get_decimal_point">
    <refnamediv>
     <refname>fann_get_decimal_point</refname>
     <refpurpose>Get the position of the decimal point.</refpurpose>
    </refnamediv>
    <refsect1>
     <title>Description</title>
     <methodsynopsis>
      <type>unsigned int</type><methodname>fann_get_decimal_point</methodname>
      <methodparam><type>struct fann *</type><parameter>ann</parameter></methodparam>
     </methodsynopsis>
     <para>
      Return the position of the decimal point in <parameter>ann</parameter>.
     </para>
    </refsect1>
   </refentry>

   <refentry id="api.fann_get_multiplier">
    <refnamediv>
     <refname>fann_get_multiplier</refname>
     <refpurpose>Get the multiplier.</refpurpose>
    </refnamediv>
    <refsect1>
     <title>Description</title>
     <methodsynopsis>
      <type></type><methodname>fann_get_multiplier</methodname>
      <methodparam><type>struct fann *</type><parameter>ann</parameter></methodparam>
     </methodsynopsis>
     <para>
      Return the multiplier that fix point data in <parameter>ann</parameter> is
      multiplied with.
     </para>
    </refsect1>
   </refentry>
  </section>

  <section id="api.sec.errors">
   <title>Error Handling</title>

   <refentry id="api.fann_get_errno">
    <refnamediv>
     <refname>fann_get_errno</refname>
     <refpurpose>Return the numerical representation of the last error.</refpurpose>
    </refnamediv>
    <refsect1>
     <title>Description</title>
     <methodsynopsis>
      <type>unsigned int</type><methodname>fann_get_errno</methodname>
      <methodparam><type>struct fann *</type><parameter>ann</parameter></methodparam>
     </methodsynopsis>
     <para>
      Returns the numerical representation of the last error. The error codes are defined
      in <!-- What do I put this in??? -->fann_errno.h<!-- /confusion -->.
     </para>
    </refsect1>
   </refentry>

   <refentry id="api.fann_get_errstr">
    <refnamediv>
     <refname>fann_get_errstr</refname>
     <refpurpose>Return the last error.</refpurpose>
    </refnamediv>
    <refsect1>
     <title>Description</title>
     <methodsynopsis>
      <type>char *</type><methodname>fann_get_errstr</methodname>
      <methodparam><type>struct fann *</type><parameter>ann</parameter></methodparam>
     </methodsynopsis>
     <para>
      Returns the last error.
     </para>
     <para>
      Note: This will reset the network's error- any subsequent calls to
      <function>fann_get_errno</function> or <function>fann_get_errstr</function>
      will yield 0 and NULL, respectively.
     </para>
    </refsect1>
   </refentry>

   <refentry id="api.fann_reset_errno">
    <refnamediv>
     <refname>fann_reset_errno</refname>
     <refpurpose>Reset the last error number.</refpurpose>
    </refnamediv>
    <refsect1>
     <title>Description</title>
     <methodsynopsis>
      <type>void</type><methodname>fann_reset_errno</methodname>
      <methodparam><type>struct fann *</type><parameter>ann</parameter></methodparam>
     </methodsynopsis>
     <para>
      Reset the last error number.
     </para>
    </refsect1>
   </refentry>

   <refentry id="api.fann_reset_errstr">
    <refnamediv>
     <refname>fann_reset_errstr</refname>
     <refpurpose>Reset the last error string.</refpurpose>
    </refnamediv>
    <refsect1>
     <title>Description</title>
     <methodsynopsis>
      <type>void</type><methodname>fann_reset_errstr</methodname>
      <methodparam><type>struct fann *</type><parameter>ann</parameter></methodparam>
     </methodsynopsis>
     <para>
      Reset the last error string.
     </para>
    </refsect1>
   </refentry>

   <refentry id="api.fann_set_error_log">
    <refnamediv>
     <refname>fann_set_error_log</refname>
     <refpurpose>Set the error log to a file descriptor.</refpurpose>
    </refnamediv>
    <refsect1>
     <title>Description</title>
     <methodsynopsis>
      <type>void</type><methodname>fann_set_error_log</methodname>
      <methodparam><type>struct fann *</type><parameter>ann</parameter></methodparam>
      <methodparam><type>FILE *</type><parameter>log</parameter></methodparam>
     </methodsynopsis>
     <para>
      Set the error log to <parameter>log</parameter>.
     </para>
     <para>
      The error log defaults to stderr.
     </para>
    </refsect1>
   </refentry>

   <refentry id="api.fann_print_error">
    <refnamediv>
     <refname>fann_print_error</refname>
     <refpurpose>Print the last error to the error log.</refpurpose>
    </refnamediv>
    <refsect1>
     <title>Description</title>
     <methodsynopsis>
      <type>void</type><methodname>fann_print_error_log</methodname>
      <methodparam><type>struct fann *</type><parameter>ann</parameter></methodparam>
     </methodsynopsis>
     <para>
      Prints the network's last error to the error log.
     </para>
     <para>
      The error log defaults to stderr.
     </para>
    </refsect1>
   </refentry>
  </section>

  <section id="api.sec.internal">
   <title>Internal Functions</title>
   <section id="api.sec.create_destroy.internal">
    <title>Creation And Destruction</title>
    <refentry id="api.fann_allocate_structure">
     <refnamediv>
      <refname>fann_allocate_structure</refname>
      <refpurpose>Allocate the core elements of a <type>struct fann</type>.</refpurpose>
     </refnamediv>
     <refsect1>
      <title>Description</title>
       <methodsynopsis>
        <type>struct fann *</type><methodname>fann_allocate_structure</methodname>
        <methodparam><type>float</type><parameter>learning_rate</parameter></methodparam>
        <methodparam><type>unsigned int</type><parameter>num_layers</parameter></methodparam>
       </methodsynopsis>
      <para>
       <function>fann_allocate_structure</function> is used internally to create a
       <type>struct fann</type>.
      </para>
     </refsect1>
    </refentry>
   </section>

   <section id="api.sec.io.internal">
    <title>Input/Output</title>
    <refentry id="api.fann_save_internal">
     <refnamediv>
     <refname>fann_save_internal</refname>
      <refpurpose>Save an ANN to a file.</refpurpose>
     </refnamediv>
     <refsect1>
      <title>Description</title>
       <methodsynopsis>
        <type>int</type><methodname>fann_save_internal</methodname>
        <methodparam><type>struct fann *</type><parameter>ann</parameter></methodparam>
        <methodparam><type>const char *</type><parameter>configuration_file</parameter></methodparam>
       <methodparam><type>unsigned int</type><parameter>save_as_fixed</parameter></methodparam>
       </methodsynopsis>
      <para>
       <function>fann_save_internal_fd</function> is used internally to save an ANN to a file.
     </para>
     </refsect1>
    </refentry>

    <refentry id="api.fann_save_internal_fd">
     <refnamediv>
     <refname>fann_save_internal_fd</refname>
      <refpurpose>Save an ANN to a file descriptor.</refpurpose>
     </refnamediv>
     <refsect1>
      <title>Description</title>
       <methodsynopsis>
        <type>int</type><methodname>fann_save_internal_fd</methodname>
        <methodparam><type>struct fann *</type><parameter>ann</parameter></methodparam>
        <methodparam><type>FILE *</type><parameter>conf</parameter></methodparam>
        <methodparam><type>const char *</type><parameter>configuration_file</parameter></methodparam>
       <methodparam><type>unsigned int</type><parameter>save_as_fixed</parameter></methodparam>
       </methodsynopsis>
      <para>
       <function>fann_save_internal_fd</function> is used internally to save an ANN to a location pointed to by
       <parameter>conf</parameter>. <parameter>configuration_file</parameter> is the name of the file, used only
       for debugging purposes.
     </para>
     </refsect1>
    </refentry>

    <refentry id="api.fann_create_from_fd">
     <refnamediv>
     <refname>fann_create_from_fd</refname>
      <refpurpose>Load an ANN from a file descriptor.</refpurpose>
     </refnamediv>
     <refsect1>
      <title>Description</title>
       <methodsynopsis>
        <type>struct fann *</type><methodname>fann_create_from_fd</methodname>
        <methodparam><type>FILE *</type><parameter>conf</parameter></methodparam>
        <methodparam><type>const char *</type><parameter>configuration_file</parameter></methodparam>
       </methodsynopsis>
      <para>
       <function>fann_create_from_fd</function> will load an ANN from a file descriptor.
      </para>
     </refsect1>
    </refentry>
   </section>

   <section id="api.sec.train_data.internal">
    <title>Training Data</title>

    <refentry id="api.fann_save_train_internal">
     <refnamediv>
      <refname>fann_save_train_internal</refname>
      <refpurpose>Save training data to a file.</refpurpose>
     </refnamediv>
     <refsect1>
      <title>Description</title>
      <methodsynopsis>
       <type>void</type><methodname>fann_save_train_internal</methodname>
       <methodparam><type>struct fann_train_data *</type><parameter>data</parameter></methodparam>
       <methodparam><type>char *</type><parameter>filename</parameter></methodparam>
       <methodparam><type>unsigned int</type><parameter>save_as_fixed</parameter></methodparam>
       <methodparam><type>unsigned int</type><parameter>decimal_point</parameter></methodparam>
      </methodsynopsis>
      <para>
       Saves the data in <parameter>data</parameter> to <parameter>filename</parameter>.
       <parameter>save_as_fixed</parameter> is either TRUE or FALSE.
       <parameter>decimal_point</parameter> tells FANN where the decimal point may be if using
       fixed point math. (Right?)
      </para>
     </refsect1>
    </refentry>

    <refentry id="api.fann_save_train_internal_fd">
     <refnamediv>
      <refname>fann_save_train_internal_fd</refname>
      <refpurpose>Save training data to a file descriptor.</refpurpose>
     </refnamediv>
     <refsect1>
      <title>Description</title>
      <methodsynopsis>
       <type>void</type><methodname>fann_save_train_internal_fd</methodname>
       <methodparam><type>struct fann_train_data *</type><parameter>data</parameter></methodparam>
       <methodparam><type>FILE *</type><parameter>file</parameter></methodparam>
       <methodparam><type>char *</type><parameter>filename</parameter></methodparam>
       <methodparam><type>unsigned int</type><parameter>save_as_fixed</parameter></methodparam>
       <methodparam><type>unsigned int</type><parameter>decimal_point</parameter></methodparam>
      </methodsynopsis>
      <para>
       Saves the data in <parameter>data</parameter> to <parameter>file</parameter>.
       <parameter>save_as_fixed</parameter> is either TRUE or FALSE.
       <parameter>decimal_point</parameter> tells FANN where the decimal point may be if using
       fixed point math. (Right?)
      </para>
      <para>
       <parameter>filename</parameter> is used for debugging output only.
      </para>
     </refsect1>
    </refentry>

    <refentry id="api.fann_read_train_from_fd">
     <refnamediv>
      <refname>fann_read_train_from_fd</refname>
      <refpurpose>Read training data from a file descriptor.</refpurpose>
     </refnamediv>
     <refsect1>
      <title>Description</title>
      <methodsynopsis>
       <type>struct fann_train_data *</type><methodname>fann_read_train_from_file</methodname>
       <methodparam><type>FILE *</type><parameter>file</parameter></methodparam>
       <methodparam><type>char *</type><parameter>filename</parameter></methodparam>
      </methodsynopsis>
      <para>
       <function>fann_read_train_from_file</function> will load training data from the file
       descriptor <parameter>file</parameter>.
      </para>
      <para>
       <parameter>filename</parameter> is used for debugging output only.
      </para>
     </refsect1>
    </refentry>
   </section>

   <section id="api.sec.io.errors">
    <title>Error Handling</title>

    <refentry id="api.fann_error">
     <refnamediv>
      <refname>fann_error</refname>
      <refpurpose>Throw an internal error.</refpurpose>
     </refnamediv>
     <refsect1>
      <title>Description</title>
      <methodsynopsis>
       <type>void</type><methodname>fann_error</methodname>
       <methodparam><type>struct fann *</type><parameter>ann</parameter></methodparam>
       <methodparam><type>unsigned int</type><parameter>errno</parameter></methodparam>
       <methodparam><parameter>...</parameter></methodparam>
      </methodsynopsis>
      <para>
       This will set the network's error to correspond to <parameter>errno</parameter>.
       The variable arguments depend (both in type and quantity) on <parameter>errno</parameter>.
       Possible <parameter>errno</parameter> values are defined in fann_errno.h.
      </para>
     </refsect1>
    </refentry>
   </section>

   <section id="api.sec.options.internal">
    <title>Options</title>

    <refentry id="api.fann_update_stepwise_hidden">
     <refnamediv>
      <refname>fann_update_stepwise_hidden</refname>
      <refpurpose>Adjust the stepwise function in the hidden layers.</refpurpose>
     </refnamediv>
     <refsect1>
      <title>Description</title>
      <methodsynopsis>
       <type>void</type><methodname>fann_update_stepwise_hidden</methodname>
       <methodparam><type>struct fann *</type><parameter>ann</parameter></methodparam>
      </methodsynopsis>
      <para>
       Update the stepwise function in the hidden layers of <parameter>ann</parameter>.
      </para>
     </refsect1>
    </refentry>

    <refentry id="api.fann_update_stepwise_output">
     <refnamediv>
      <refname>fann_update_stepwise_output</refname>
      <refpurpose>Adjust the stepwise functions in the output layers.</refpurpose>
     </refnamediv>
     <refsect1>
      <title>Description</title>
      <methodsynopsis>
       <type>void</type><methodname>fann_update_stepwise_output</methodname>
       <methodparam><type>struct fann *</type><parameter>ann</parameter></methodparam>
      </methodsynopsis>
      <para>
       Update the stepwise function in the output layers of <parameter>ann</parameter>.
      </para>
     </refsect1>
    </refentry>
   </section>
  </section>

  <section id="api.sec.deprecated">
   <title>Deprecated Functions</title>

   <section id="api.sec.error.deprecated">
    <title>Error Handling</title>

    <refentry id="api.fann_get_error">
     <refnamediv>
      <refname>fann_get_error</refname>
      <refpurpose>Return the mean square error of an ANN.</refpurpose>
     </refnamediv>
     <refsect1>
      <title>Description</title>
      <methodsynopsis>
       <type>float</type><methodname>fann_get_error</methodname>
       <methodparam><type>struct fann *</type><parameter>ann</parameter></methodparam>
      </methodsynopsis>
      <para>
       This function is deprecated and will be removed in a future version. Use
       <link linkend="api.fann_get_MSE"><function>fann_get_MSE</function></link> instead.
      </para>
     </refsect1>
    </refentry>

    <refentry id="api.fann_reset_error">
     <refnamediv>
      <refname>fann_get_error</refname>
      <refpurpose>Reset the mean square error of an ANN.</refpurpose>
     </refnamediv>
     <refsect1>
      <title>Description</title>
      <methodsynopsis>
       <type>void</type><methodname>fann_reset_error</methodname>
       <methodparam><type>struct fann *</type><parameter>ann</parameter></methodparam>
      </methodsynopsis>
      <para>
       This function is deprecated and will be removed in a future version. Use
       <link linkend="api.fann_reset_MSE"><function>fann_reset_MSE</function></link> instead.
      </para>
     </refsect1>
    </refentry>
   </section>
  </section>
 </chapter>

 <chapter id="php">
  <title>PHP Extension</title>
  <para>
   These functions allow you to interact with the FANN library from PHP.
  </para>
  <para>
   This extension requires the
   <ulink url="http://fann.sf.net/">FANN</ulink> library,
   version 1.0.6 or later.
  </para>
  <para>
   The following activation functions are supported:
   <itemizedlist>
    <listitem><simpara>FANN_SIGMOID</simpara></listitem>
    <listitem><simpara>FANN_THRESHOLD</simpara></listitem>
    <listitem><simpara>FANN_SIGMOID_STEPWISE</simpara></listitem>
   </itemizedlist>
  </para>

  <section id="php.api">
   <title>API Reference</title>
   <refentry id="function.fann_create">
    <refnamediv>
     <refname>fann_create</refname>
     <refpurpose>Creates an artificial neural network.</refpurpose>
    </refnamediv>
    <refsect1>
     <title>Description</title>
      <methodsynopsis>
       <type>mixed</type><methodname>fann_create</methodname>
       <methodparam><type>array</type><parameter>data</parameter></methodparam>
       <methodparam choice="opt"><type>float</type><parameter>connection_rate</parameter></methodparam>
       <methodparam choice="opt"><type>float</type><parameter>learning_rate</parameter></methodparam>
      </methodsynopsis>
     <para>
      <function>fann_create</function> will create an artificial neural
      network using the data given.
     </para>
     <para>
      If the first parameter is an array, <function>fann_create</function>
      will use the data and structure of the array, as well as
      <parameter>connection_rate</parameter> and
      <parameter>learning_rate</parameter>.
     </para>
     <para>
      If <function>fann_create</function> is called with a sole string argument,
      it will attempt to load an ANN created with <function>fann_save</function>
      from the file at <parameter>filename</parameter>.
     </para>
     <para>
      <function>fann_create</function> will return the artificial neural network
      on success, or FALSE if it fails.
     </para>
     <para>
      <example>
       <title><function>fann_create</function> from scratch</title>
       <programlisting role="php">
<![CDATA[
<?php
$ann = fann_create(
  /* Layers. In this case, three layers-
   * two input neurons, 4 neurons on a
   * hidden layer, and one output neuron. */
  array(2, 4, 1),
  1.0,
  0.7);
?>
]]>
       </programlisting>
      </example>
     </para>
     <para>
      <example>
       <title><function>fann_create</function> loading from a file</title>
       <programlisting role="php">
<![CDATA[
<?php
$ann = fann_create("http://www.example.com/ann.net");
);
?>
]]>
       </programlisting>
      </example>
     </para>
     <para>
      See also <function>fann_save</function>.
     </para>
    </refsect1>
   </refentry>

   <refentry id="function.fann_train">
    <refnamediv>
     <refname>fann_train</refname>
     <refpurpose>Train an artificial neural network.</refpurpose>
    </refnamediv>
    <refsect1>
     <title>Description</title>
      <methodsynopsis>
       <type>bool</type><methodname>fann_train</methodname>
       <methodparam><type>resource</type><parameter>ann</parameter></methodparam>
       <methodparam><type>mixed</type><parameter>data</parameter></methodparam>
       <methodparam><type>int</type><parameter>max_iterations</parameter></methodparam>
       <methodparam><type>double</type><parameter>desired_error</parameter></methodparam>
       <methodparam choice="opt"><type>int</type><parameter>iterations_between_reports</parameter></methodparam>
      </methodsynopsis>
     <para>
      <function>fann_train</function> will train <parameter>ann</parameter> on
      the data supplied, returning TRUE on success or FALSE on failure.
     </para>
     <para>
      Resources is anrtificial neural network returned by <function>fann_create</function>.
     </para>
     <para>
      <parameter>data</parameter> must be either an array of training data, or
      the URI of a properly formatted training file.
     </para>
     <para>
      <function>fann_train</function> will continue training until
      <parameter>desired_error</parameter> is reached, or
      <parameter>max_iterations</parameter> is exceeded.
     </para>
     <para>
      If <parameter>iterations_between_reports</parameter> is set,
      <function>fann_create</function> will output a short progress
      report every <parameter>iterations_between_reports</parameter>.
      Default is 0 (meaning no reports).
     </para>
     <para>
      <example>
       <title><function>fann_create</function> from training data</title>
       <programlisting role="php">
<![CDATA[
<?php
$ann = fann_create(array(2, 4, 1), 1.0, 0.7);
if ( fann_train($ann,
	   array(
		 array(
		       array(0,0), /* Input(s) */
		       array(0) /* Output(s) */
		       ),
		 array(
		       array(0,1), /* Input(s) */
		       array(1) /* Output(s) */
		       ),
		 array(
		       array(1,0), /* Input(s) */
		       array(1) /* Output(s) */
		       ),
		 array(array(1,1), /* Input(s) */
		       array(0) /* Output(s) */
		       )
		 ),
	   100000,
	   0.00001,
	   1000) == FALSE) {
  exit('Could not train $ann.');
}
?>
]]>
       </programlisting>
      </example>
     </para>
    </refsect1>
   </refentry>

   <refentry id="function.fann_save">
    <refnamediv>
     <refname>fann_save</refname>
     <refpurpose>Save an artificial neural network to a file.</refpurpose>
    </refnamediv>
    <refsect1>
     <title>Description</title>
      <methodsynopsis>
       <type>bool</type><methodname>fann_save</methodname>
       <methodparam><type>resource</type><parameter>ann</parameter></methodparam>
       <methodparam><type>string</type><parameter>filename</parameter></methodparam>
      </methodsynopsis>
     <para>
      <function>fann_save</function> will save <parameter>ann</parameter> to
      <parameter>filename</parameter>, returning TRUE on success or FALSE on failure.
     </para>
     <para>
      See also <function>fann_create</function>.
     </para>
    </refsect1>
   </refentry>

   <refentry id="function.fann_run">
    <refnamediv>
     <refname>fann_run</refname>
     <refpurpose>Run an artificial neural network.</refpurpose>
    </refnamediv>
    <refsect1>
     <title>Description</title>
      <methodsynopsis>
       <type>mixed</type><methodname>fann_run</methodname>
       <methodparam><type>resource</type><parameter>ann</parameter></methodparam>
       <methodparam><type>array</type><parameter>input</parameter></methodparam>
      </methodsynopsis>
     <para>
      <function>fann_run</function> will run <parameter>input</parameter> through
      <parameter>ann</parameter>, returning an an ouput array on success or FALSE
      on failure.
     </para>
     <para>
      <example>
       <title><function>fann_run</function> Example</title>
       <programlisting role="php">
<![CDATA[
<?php
if ( ($ann = fann_create("http://www.example.com/ann.net")) == FALSE )
  exit("Could not create ANN.");
if ( fann_train($ann, "http://www.example.com/train.data", 100000, 0.00001) == FALSE )
  exit("Could not train ANN.");

if ( ($output = fann_run($ann, array(0, 1))) == FALSE )
  exit("Could not run ANN.");
else
  print_r($output);
?>
]]>
       </programlisting>
      </example>
     </para>
    </refsect1>
   </refentry>

   <refentry id="function.fann_randomize_weights">
    <refnamediv>
     <refname>fann_randomize_weights</refname>
     <refpurpose>Randomize the weights of the neurons in the network.</refpurpose>
    </refnamediv>
    <refsect1>
     <title>Description</title>
      <methodsynopsis>
       <type>void</type><methodname>fann_save</methodname>
       <methodparam><type>resource</type><parameter>ann</parameter></methodparam>
       <methodparam choice="opt"><type>float</type><parameter>minimum</parameter></methodparam>
       <methodparam choice="opt"><type>float</type><parameter>maximum</parameter></methodparam>
      </methodsynopsis>
     <para>
      <function>fann_randomize_weights</function> will randomize the weights of all neurons in
      <parameter>ann</parameter>, effectively resetting the network.
     </para>
    </refsect1>
   </refentry>

   <refentry id="function.fann_get_MSE">
    <refnamediv>
     <refname>fann_get_MSE</refname>
     <refpurpose>Get the mean squared error.</refpurpose>
    </refnamediv>
    <refsect1>
     <title>Description</title>
      <methodsynopsis>
       <type>float</type><methodname>fann_get_MSE</methodname>
       <methodparam><type>resource</type><parameter>ann</parameter></methodparam>
      </methodsynopsis>
     <para>
      <function>fann_get_MSE</function> will return the mean squared error (MSE) of
      <parameter>ann</parameter>, or 0 if it is unavailable.
     </para>
    </refsect1>
   </refentry>

   <refentry id="function.fann_get_num_input">
    <refnamediv>
     <refname>fann_get_num_input</refname>
     <refpurpose>Get the number of input neurons.</refpurpose>
    </refnamediv>
    <refsect1>
     <title>Description</title>
      <methodsynopsis>
       <type>int</type><methodname>fann_get_num_input</methodname>
       <methodparam><type>resource</type><parameter>ann</parameter></methodparam>
      </methodsynopsis>
     <para>
      <function>fann_get_num_input</function> will return the number of input neurons in
      <parameter>ann</parameter>.
     </para>
     <para>
      See also <function>fann_get_num_output</function>, <function>fann_get_total_neurons</function>.
     </para>
    </refsect1>
   </refentry>

   <refentry id="function.fann_get_num_output">
    <refnamediv>
     <refname>fann_get_num_output</refname>
     <refpurpose>Get the number of output neurons.</refpurpose>
    </refnamediv>
    <refsect1>
     <title>Description</title>
      <methodsynopsis>
       <type>int</type><methodname>fann_get_num_output</methodname>
       <methodparam><type>resource</type><parameter>ann</parameter></methodparam>
      </methodsynopsis>
     <para>
      <function>fann_get_num_output</function> will return the number of output neurons in
      <parameter>ann</parameter>.
     </para>
     <para>
      See also <function>fann_get_num_input</function>, <function>fann_get_total_neurons</function>.
     </para>
    </refsect1>
   </refentry>

   <refentry id="function.fann_get_total_neurons">
    <refnamediv>
     <refname>fann_get_total_neurons</refname>
     <refpurpose>Get the total number of neurons.</refpurpose>
    </refnamediv>
    <refsect1>
     <title>Description</title>
      <methodsynopsis>
       <type>int</type><methodname>fann_get_total_neurons</methodname>
       <methodparam><type>resource</type><parameter>ann</parameter></methodparam>
      </methodsynopsis>
     <para>
      <function>fann_get_total_neurons</function> will return the total number of neurons in
      <parameter>ann</parameter>.
     </para>
     <para>
      See also <function>fann_get_num_input</function>, <function>fann_get_num_output</function>.
     </para>
    </refsect1>
   </refentry>

   <refentry id="function.fann_get_total_connections">
    <refnamediv>
     <refname>fann_get_total_connections</refname>
     <refpurpose>Get the total number of connections.</refpurpose>
    </refnamediv>
    <refsect1>
     <title>Description</title>
      <methodsynopsis>
       <type>int</type><methodname>fann_get_total_connections</methodname>
       <methodparam><type>resource</type><parameter>ann</parameter></methodparam>
      </methodsynopsis>
     <para>
      <function>fann_get_total_connections</function> will return the total number of connections in
      <parameter>ann</parameter>.
     </para>
    </refsect1>
   </refentry>

   <refentry id="function.fann_get_learning_rate">
    <refnamediv>
     <refname>fann_get_learning_rate</refname>
     <refpurpose>Get the learning rate.</refpurpose>
    </refnamediv>
    <refsect1>
     <title>Description</title>
      <methodsynopsis>
       <type>float</type><methodname>fann_get_learning_rate</methodname>
       <methodparam><type>resource</type><parameter>ann</parameter></methodparam>
      </methodsynopsis>
     <para>
      <function>fann_get_learning_rate</function> will return the learning rate of
      <parameter>ann</parameter>.
     </para>
     <para>
      See also <function>fann_set_learning_rate</function>.
     </para>
    </refsect1>
   </refentry>

   <refentry id="function.fann_get_activation_function_hidden">
    <refnamediv>
     <refname>fann_get_activation_function_hidden</refname>
     <refpurpose>Get the activation function of the hidden neurons.</refpurpose>
    </refnamediv>
    <refsect1>
     <title>Description</title>
      <methodsynopsis>
       <type>int</type><methodname>fann_get_activation_function_hidden</methodname>
       <methodparam><type>resource</type><parameter>ann</parameter></methodparam>
      </methodsynopsis>
     <para>
      <function>fann_get_activation_function_hidden</function> will return the activation function
      for the hidden neurons in <parameter>ann</parameter>.
     </para>
     <para>
      See also <function>fann_set_activation_function_hidden</function>.
     </para>
    </refsect1>
   </refentry>

   <refentry id="function.fann_get_activation_function_output">
    <refnamediv>
     <refname>fann_get_activation_function_output</refname>
     <refpurpose>Get the activation function of the output neurons.</refpurpose>
    </refnamediv>
    <refsect1>
     <title>Description</title>
      <methodsynopsis>
       <type>int</type><methodname>fann_get_activation_function_output</methodname>
       <methodparam><type>resource</type><parameter>ann</parameter></methodparam>
      </methodsynopsis>
     <para>
      <function>fann_get_activation_function_output</function> will return the activation function
      for the output neurons in <parameter>ann</parameter>.
     </para>
     <para>
      See also <function>fann_set_activation_function_output</function>.
     </para>
    </refsect1>
   </refentry>

   <refentry id="function.fann_get_activation_hidden_steepness">
    <refnamediv>
     <refname>fann_get_activation_hidden_steepness</refname>
     <refpurpose>Get the steepness of the activation function for the hidden neurons.</refpurpose>
    </refnamediv>
    <refsect1>
     <title>Description</title>
      <methodsynopsis>
       <type>float</type><methodname>fann_get_activation_hidden_steepness</methodname>
       <methodparam><type>resource</type><parameter>ann</parameter></methodparam>
      </methodsynopsis>
     <para>
      <function>fann_get_activation_hidden_steepness</function> will return the steepness of the
      activation function for the hidden neurons in <parameter>ann</parameter>.
     </para>
     <para>
      See also <function>fann_set_activation_function_hidden_steepness</function>.
     </para>
    </refsect1>
   </refentry>

   <refentry id="function.fann_get_activation_output_steepness">
    <refnamediv>
     <refname>fann_get_activation_output_steepness</refname>
     <refpurpose>Get the steepness of the activation function for the output neurons.</refpurpose>
    </refnamediv>
    <refsect1>
     <title>Description</title>
      <methodsynopsis>
       <type>float</type><methodname>fann_get_activation_output_steepness</methodname>
       <methodparam><type>resource</type><parameter>ann</parameter></methodparam>
      </methodsynopsis>
     <para>
      <function>fann_get_activation_output_steepness</function> will return the steepness of the
      activation function for the output neurons in <parameter>ann</parameter>.
     </para>
     <para>
      See also <function>fann_set_activation_output_steepness</function>.
     </para>
    </refsect1>
   </refentry>

   <refentry id="function.fann_set_learning_rate">
    <refnamediv>
     <refname>fann_set_learning_rate</refname>
     <refpurpose>Set the learning rate.</refpurpose>
    </refnamediv>
    <refsect1>
     <title>Description</title>
      <methodsynopsis>
       <type>float</type><methodname>fann_set_learning_rate</methodname>
       <methodparam><type>resource</type><parameter>ann</parameter></methodparam>
      </methodsynopsis>
     <para>
      <function>fann_set_learning_rate</function> will return the learning rate of
      <parameter>ann</parameter>.
     </para>
     <para>
      See also <function>fann_set_learning_rate</function>.
     </para>
    </refsect1>
   </refentry>

   <refentry id="function.fann_set_activation_function_hidden">
    <refnamediv>
     <refname>fann_set_activation_function_hidden</refname>
     <refpurpose>Set the activation function for the hidden neurons.</refpurpose>
    </refnamediv>
    <refsect1>
     <title>Description</title>
      <methodsynopsis>
       <type>void</type><methodname>fann_set_activation_function_hidden</methodname>
       <methodparam><type>resource</type><parameter>ann</parameter></methodparam>
       <methodparam><type>int</type><parameter>activation_function</parameter></methodparam>
      </methodsynopsis>
     <para>
      <function>fann_set_activation_function_hidden</function> sets the activation function
      for the hidden neurons to <parameter>activation_function</parameter>, which must be one
      of the supported activation functions.
     </para>
     <para>
      See also <function>fann_get_activation_function_hidden</function>.
     </para>
    </refsect1>
   </refentry>

   <refentry id="function.fann_set_activation_function_output">
    <refnamediv>
     <refname>fann_set_activation_function_output</refname>
     <refpurpose>Set the activation function for the output neurons.</refpurpose>
    </refnamediv>
    <refsect1>
     <title>Description</title>
      <methodsynopsis>
       <type>void</type><methodname>fann_set_activation_function_output</methodname>
       <methodparam><type>resource</type><parameter>ann</parameter></methodparam>
       <methodparam><type>int</type><parameter>activation_function</parameter></methodparam>
      </methodsynopsis>
     <para>
      <function>fann_set_activation_function_output</function> sets the activation function
      for the output neurons to <parameter>activation_function</parameter>, which must be one
      of the supported activation functions.
     </para>
     <para>
      See also <function>fann_get_activation_function_output</function>.
     </para>
    </refsect1>
   </refentry>

   <refentry id="function.fann_set_activation_hidden_steepness">
    <refnamediv>
     <refname>fann_set_activation_hidden_steepness</refname>
     <refpurpose>Set the steepness of the activation function for the hidden neurons.</refpurpose>
    </refnamediv>
    <refsect1>
     <title>Description</title>
      <methodsynopsis>
       <type>void</type><methodname>fann_set_activation_hidden_steepness</methodname>
       <methodparam><type>resource</type><parameter>ann</parameter></methodparam>
       <methodparam><type>float</type><parameter>steepness</parameter></methodparam>
      </methodsynopsis>
     <para>
      <function>fann_set_activation_hidden_steepness</function> sets the steepness of the
      activation function hidden neurons to <parameter>steepness</parameter>.
     </para>
     <para>
      See also <function>fann_get_activation_hidden_steepness</function>.
     </para>
    </refsect1>
   </refentry>

   <refentry id="function.fann_set_activation_output_steepness">
    <refnamediv>
     <refname>fann_set_activation_output_steepness</refname>
     <refpurpose>Set the steepness of the activation function for the output neurons.</refpurpose>
    </refnamediv>
    <refsect1>
     <title>Description</title>
     <methodsynopsis>
      <type>void</type><methodname>fann_set_activation_output_steepness</methodname>
      <methodparam><type>resource</type><parameter>ann</parameter></methodparam>
      <methodparam><type>float</type><parameter>steepness</parameter></methodparam>
     </methodsynopsis>
     <para>
      <function>fann_set_activation_output_steepness</function> sets the steepness of the
      activation function output neurons to <parameter>steepness</parameter>.
     </para>
     <para>
      See also <function>fann_get_activation_output_steepness</function>.
     </para>
    </refsect1>
   </refentry>
  </section>
 </chapter>
 <bibliography id="bibliography">
  <title>Bibliography</title>

  <biblioentry id="bib.tettamanzi_2001">
   <abbrev id="bib.tettamanzi_2001.abbrev">[Tettamanzi and Tomassini, 2001]</abbrev>
   <author>
    <firstname>A.</firstname>
    <surname>Tettamanzi</surname>
   </author>
   <author>
    <firstname>M.</firstname>
    <surname>Tomassini</surname>
   </author>
   <pubdate></pubdate>
   <title>Soft Computing</title>
   <publishername>Springer-Verlag</publishername>
  </biblioentry>

  <biblioentry id="bib.anderson_1995">
   <abbrev id="bib.anderson_1995.abbrev">[Anderson, 1995]</abbrev>
   <author>
    <firstname>J.A.</firstname>
    <surname>Anderson</surname>
   </author>
   <pubdate>1995</pubdate>
   <title>An Introduction to Neural Networks</title>
   <publishername>The MIT Press</publishername>
  </biblioentry>

  <biblioentry id="bib.anguita_1993">
   <abbrev id="bib.anguita_1993.abbrev">[Anguita, 1993]</abbrev>
   <author>
    <firstname>D.</firstname>
    <surname>Anguita</surname>
   </author>
   <title>Matrix back propagation v1.1</title>
  </biblioentry>

  <biblioentry id="bib.bentley_1982">
   <abbrev id="bib.bently_1982.abbrev">[Bentley, 1982]</abbrev>
   <author>
    <firstname>J.L.</firstname>
    <surname>Bentley</surname>
   </author>
   <pubdate>1982</pubdate>
   <title>Writing Efficient Programs</title>
   <publishername>Prentice-Hall</publishername>
  </biblioentry>

  <biblioentry id="bib.blake_1998">
   <abbrev id="bib.blake_1998.abbrev">[Blake and Merz, 1998]</abbrev>
   <author>
    <firstname>C.</firstname>
    <surname>Blake</surname>
   </author>
   <author>
    <firstname>C.</firstname>
    <surname>Merz</surname>
   </author>
   <pubdate>1998</pubdate>
   <title>UCI repository of machine learning databases</title>
   <releaseinfo><ulink url="http://www.ics.uci.edu/mlearn/MLRepository.html">http://www.ics.uci.edu/mlearn/MLRepository.html</ulink></releaseinfo>
   <publishername></publishername>
  </biblioentry>

  <biblioentry id="bib.darrington_2003">
   <abbrev id="bib.darrington_2003.abbrev">[Darrington, 2003]</abbrev>
   <author>
    <firstname>J.</firstname>
    <surname>Darrington</surname>
   </author>
   <pubdate>2003</pubdate>
   <title>Libann</title>
   <releaseinfo><ulink url="http://www.nongnu.org/libann/index.html">http://www.nongnu.org/libann/index.html</ulink></releaseinfo>
  </biblioentry>

  <biblioentry id="bib.fahlman_1988">
   <abbrev id="bib.fahlman_1988.abbrev">[Falhman, 1988]</abbrev>
   <author>
    <firstname>S.E.</firstname>
    <surname>Fahlman</surname>
   </author>
   <pubdate>1988</pubdate>
   <title>Faster-learning variations on back-propagation</title>
   <subtitle>An empirical stody</subtitle>
  </biblioentry>

  <biblioentry id="bib.FSF_1999">
   <abbrev id="bib.FSF_1999.abbrev">[LGPL]</abbrev>
   <author>
    <surname>Free Software Foundation</surname>
   </author>
   <pubdate>1999</pubdate>
   <title>GNU Lesser General Public License</title>
   <publishername>Free Software Foundation</publishername>
   <releaseinfo><ulink url="http://www.fsf.org/copyleft/lesser.html">http://www.fsf.org/copyleft/lesser.html</ulink></releaseinfo>
  </biblioentry>

  <biblioentry id="bib.hassoun_1995">
   <abbrev id="bib.hassoun_1995.abbrev">[Hassoun, 1995]</abbrev>
   <author>
    <firstname>M.H.</firstname>
    <surname>Hassoun</surname>
   </author>
   <pubdate>1995</pubdate>
   <title>Fundamentals of Artificial Neural Networks</title>
   <publishername>The MIT Press</publishername>
  </biblioentry>

  <biblioentry id="bib.heller_2002">
   <abbrev id="bib.heller_2002.abbrev">[Heller, 2002]</abbrev>
   <author>
    <firstname>J.</firstname>
    <surname>Heller</surname>
   </author>
   <pubdate>2002</pubdate>
   <title>Jet's Neural Library</title>
   <releaseinfo><ulink url="http://www.voltar.org/jneural/jneural_doc/">http://www.voltar.org/jneural/jneural_doc/</ulink></releaseinfo>
  </biblioentry>

  <biblioentry id="bib.hertz_1991">
   <abbrev id="bib.hertz_1991.abbrev">[Hertz et al., 1991]</abbrev>
   <author>
    <firstname>J.</firstname>
    <surname>Hertz</surname>
   </author>
   <author>
    <firstname>A.</firstname>
    <surname>Krogh</surname>
   </author>
   <author>
    <firstname>R.G.</firstname>
    <surname>Palmer</surname>
   </author>
   <pubdate>1991</pubdate>
   <title>Introduction to The Theory of Neural Computing</title>
   <publishername>Addison-Wesley Publishing Company</publishername>
  </biblioentry>

  <biblioentry id="bib.IDS_2000">
   <abbrev id="bib.IDS_2000.abbrev">[IDS, 2000]</abbrev>
   <author>
    <surname>ID Software</surname>
   </author>
   <pubdate>2000</pubdate>
   <title>Quake III Arena</title>
   <releaseinfo><ulink url="http://www.idsoftware.com/games/quake/quake3-arena/">http://www.idsoftware.com/games/quake/quake3-arena/</ulink></releaseinfo>
  </biblioentry>

  <biblioentry id="bib.kaelbling_1996">
   <abbrev id="bib.kaelbling_1996.abbrev">[Kaelbling, 1996]</abbrev>
   <author>
    <firstname>L.P.</firstname>
    <surname>Kaelbling</surname>
   </author>
   <author>
    <firstname>M.L.</firstname>
    <surname>Littman</surname>
   </author>
   <author>
    <firstname>A.P.</firstname>
    <surname>Moore</surname>
   </author>
   <pubdate>1996</pubdate>
   <title>Reinforcement Learning</title>
   <subtitle>A New Survey</subtitle>
   <publishername>Journal of Artificial Intelligence Research</publishername>
   <volumenum>4</volumenum>
   <pagenums>237-285</pagenums>
  </biblioentry>

  <biblioentry id="bib.lecun_1990">
   <abbrev id="bib.lecun_1990.abbrev">[LeCun et al., 1990]</abbrev>
   <author>
    <firstname>Y.</firstname>
    <surname>LeCun</surname>
   </author>
   <author>
    <firstname>J.</firstname>
    <surname>Denker</surname>
   </author>
   <author>
    <firstname>S.</firstname>
    <surname>Solla</surname>
   </author>
   <author>
    <firstname>R.E.</firstname>
    <surname>Howard</surname>
   </author>
   <author>
    <firstname>L.D.</firstname>
    <surname>Jackel</surname>
   </author>
   <pubdate>1990</pubdate>
   <title>Advances in Neural Information Processing Systems II</title>
  </biblioentry>

  <biblioentry id="bib.nissen_2003">
   <abbrev id="bib.nissen_2003.abbrev">[Nissen et al., 2003]</abbrev>
   <author>
    <firstname>S.</firstname>
    <surname>Nissen</surname>
   </author>
   <author>
    <firstname>J.</firstname>
    <surname>Damkjr</surname>
   </author>
   <author>
    <firstname>J.</firstname>
    <surname>Hansson</surname>
   </author>
   <author>
    <firstname>S.</firstname>
    <surname>Larsen</surname>
   </author>
   <author>
    <firstname>S.</firstname>
    <surname>Jensen</surname>
   </author>
   <pubdate>2003</pubdate>
   <title>Real-time image processing of an ipaq based robot with fuzzy logic (fuzzy)</title>
   <releaseinfo><ulink url="http://www.hamster.dk/~purple/robot/fuzzy/weblog/">http://www.hamster.dk/~purple/robot/fuzzy/weblog/</ulink></releaseinfo>
  </biblioentry>

  <biblioentry id="bib.nissen_2002">
   <abbrev id="bib.nissen_2002.abbrev">[Nissen et al., 2002]</abbrev>
   <author>
    <firstname>S.</firstname>
    <surname>Nissen</surname>
   </author>
   <author>
    <firstname>S.</firstname>
    <surname>Larsen</surname>
   </author>
   <author>
    <firstname>S.</firstname>
    <surname>Jensen</surname>
   </author>
   <pubdate>2003</pubdate>
   <title>Real-time image processing of an iPAQ based robot (iBOT)</title>
   <releaseinfo><ulink url="http://www.hamster.dk/~purple/robot/iBOT/report.pdf">http://www.hamster.dk/~purple/robot/iBOT/report.pdf</ulink></releaseinfo>
  </biblioentry>

  <biblioentry id="bib.OSDN_2003">
   <abbrev id="bib.OSDN_2003.abbrev">[OSDN, 2003]</abbrev>
   <pubdate>2003</pubdate>
   <title>SourceForge.net</title>
   <releaseinfo><ulink url="http://sourceforge.net/">http://sourceforge.net/</ulink></releaseinfo>
  </biblioentry>

  <biblioentry id="bib.pendleton_1993">
   <abbrev id="bib.pendleton_1993.abbrev">[Pendleton, 1993]</abbrev>
   <author>
    <firstname>R.C.</firstname>
    <surname>Pendleton</surname>
   </author>
   <pubdate>1993</pubdate>
   <title>Doing it Fast</title>
   <releaseinfo><ulink url="http://www.gameprogrammer.com/4-fixed.html">http://www.gameprogrammer.com/4-fixed.html</ulink></releaseinfo>
  </biblioentry>

  <biblioentry id="bib.prechelt_1994">
   <abbrev id="bib.prechelt_1994.abbrev">[Prechelt, 1994]</abbrev>
   <author>
    <firstname>L.</firstname>
    <surname>Prechelt</surname>
   </author>
   <pubdate>1994</pubdate>
   <title>Proben1</title>
   <subtitle>A set of neural network benchmark problems and benchmarking rules</subtitle>
  </biblioentry>

  <biblioentry id="bib.riedmiller_1993">
   <abbrev id="bib.riedmiller_1993.abbrev">[Riedmiller and Braun, 1993]</abbrev>
   <author>
    <firstname></firstname>
    <surname>Riedmiller</surname>
   </author>
   <author>
    <firstname></firstname>
    <surname>Braun</surname>
   </author>
   <pubdate>1993</pubdate>
   <title>A direct adaptive method for faster backpropagation learning: The RPROP algorithm</title>
   <pagenums>586-591</pagenums>
   <releaseinfo><ulink url="http://citeseer.nj.nec.com/riedmiller93direct.html">http://citeseer.nj.nec.com/riedmiller93direct.html</ulink></releaseinfo>
  </biblioentry>

<!-- TODO:

Sarle, 2002 
Sarle, W. S. (2002). 
Neural network faq. 

ftp://ftp.sas.com/pub/neural/FAQ2.html#A_binary. 

Software, 2002 
Software, W. (2002). 
Ann++. 

http://savannah.nongnu.org/projects/annpp/. 

Tettamanzi and Tomassini, 2001 
Tettamanzi, A. and Tomassini, M. (2001). 
Soft Computing. 
Springer-Verlag. 

van Rossum, 2003 
van Rossum, P. (2003). 
Lightweight neural network. 

http://lwneuralnet.sourceforge.net/. 

van Waveren, 2001 
van Waveren, J. P. (2001). 
The quake III arena bot. 

http://www.kbs.twi.tudelft.nl/Publications/MSc/2001-VanWaveren-MSc.html. 

Zell, 2003 
Zell, A. (2003). 
Stuttgart neural network simulator. 

http://www-ra.informatik.uni-tuebingen.de/SNNS/.
-->
 </bibliography>
</book>

<!-- Keep this comment at the end of the file
Local variables:
mode: sgml
sgml-omittag:t
sgml-shorttag:t
sgml-minimize-attributes:nil
sgml-always-quote-attributes:t
sgml-indent-step:1
sgml-indent-data:t
sgml-parent-document:nil
sgml-default-dtd-file:"../../manual.ced"
sgml-exposed-tags:nil
sgml-local-catalogs:nil
sgml-local-ecat-files:nil
End:
-->

